{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Medial axis detection of Moving Objects"
      ],
      "metadata": {
        "id": "JvtAzYDW2oW4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing Libraries"
      ],
      "metadata": {
        "id": "d1m92tzAinnZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install gdown\n",
        "import gdown\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import math\n",
        "import random\n",
        "import statistics\n",
        "from os.path import isfile, join\n",
        "import shutil"
      ],
      "metadata": {
        "id": "DRCLRKJQjLA9"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **\"Video Frame Extraction, Background Subtraction, Cleaning, and Edge Detection Pipeline\"**\n",
        "\n",
        "\n",
        "1. **Frame Extraction**: Extracts individual frames from a video file and saves them as image files.\n",
        "2. **Background Subtraction**: Removes background from extracted frames using a Gaussian Mixture Model (MOG2).\n",
        "3. **Image Cleaning**: Applies morphological operations (erosion, dilation, opening, closing, etc.) to clean and enhance the frames.\n",
        "4. **Edge Detection**: Detects edges in the processed frames using methods such as Laplacian, Sobel (X, Y, or combined), and Canny edge detection.\n",
        "\n"
      ],
      "metadata": {
        "id": "yJa--Mg54ZiD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ExtractFrames(video):\n",
        "    r_path = f'./Videos/{video}.mp4'\n",
        "    video_frame = cv2.VideoCapture(r_path)\n",
        "    w_path = './Frames'\n",
        "    os.makedirs(w_path, exist_ok=True)\n",
        "    fps = video_frame.get(cv2.CAP_PROP_FPS)\n",
        "    print(f\"Frames per second: {fps}\")\n",
        "    No_of_frames = int(video_frame.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    print(f\"Number of frames: {No_of_frames}\")\n",
        "    i = 0\n",
        "    while True:\n",
        "        success, frame = video_frame.read()\n",
        "        if not success:\n",
        "            break\n",
        "        frame_filename = os.path.join(w_path, f'Frame{i}_{video}.jpg')\n",
        "        cv2.imwrite(frame_filename, frame)\n",
        "        i += 1\n",
        "    video_frame.release()\n",
        "    return fps\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "def BgSubtract(video, fps, varThreshold):\n",
        "    w_path = './Background-Subtraction-Frames'\n",
        "    os.makedirs(w_path, exist_ok=True)\n",
        "    r_path = './Frames'\n",
        "    Subtraction_MOG = cv2.createBackgroundSubtractorMOG2(\n",
        "        history=int(10 * fps), detectShadows=True, varThreshold=varThreshold\n",
        "    )\n",
        "    for img_name in os.listdir(r_path):\n",
        "        if not img_name.startswith(f'Frame') or not img_name.endswith(f'_{video}.jpg'):\n",
        "            continue\n",
        "        frame_path = os.path.join(r_path, img_name)\n",
        "        frame = cv2.imread(frame_path)\n",
        "        if frame is None:\n",
        "            print(f\"Warning: Unable to read {frame_path}. Skipping.\")\n",
        "            continue\n",
        "        Image_foreground = Subtraction_MOG.apply(frame)\n",
        "        Image_foreground[Image_foreground == 127] = 0\n",
        "        output_path = os.path.join(w_path, img_name)\n",
        "        cv2.imwrite(output_path, Image_foreground)\n",
        "    print(\"Background subtraction completed and images saved to:\", w_path)\n",
        "\n",
        "def Cleaning(video, operation_type, kernel_size, structural=\"no\", size=100):\n",
        "    w_path = './Image-Cleaning-Results'\n",
        "    r_path = './Background-Subtraction-Frames'\n",
        "    os.makedirs(w_path, exist_ok=True)\n",
        "    kernel = np.ones((kernel_size, kernel_size), np.uint8)\n",
        "    for img_name in os.listdir(r_path):\n",
        "        if not img_name.endswith(f'_{video}.jpg'):\n",
        "            continue\n",
        "        img_path = os.path.join(r_path, img_name)\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is None:\n",
        "            print(f\"Warning: Unable to read {img_path}. Skipping.\")\n",
        "            continue\n",
        "        if operation_type == \"erosion\":\n",
        "            out = cv2.erode(img, kernel, iterations=1)\n",
        "        elif operation_type == \"dilation\":\n",
        "            out = cv2.dilate(img, kernel, iterations=1)\n",
        "        elif operation_type == \"opening\":\n",
        "            out = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)\n",
        "        elif operation_type == \"closing\":\n",
        "            out = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)\n",
        "        elif operation_type == \"gradient\":\n",
        "            out = cv2.morphologyEx(img, cv2.MORPH_GRADIENT, kernel)\n",
        "        elif operation_type == \"tophat\":\n",
        "            out = cv2.morphologyEx(img, cv2.MORPH_TOPHAT, kernel)\n",
        "        elif operation_type == \"blackhat\":\n",
        "            out = cv2.morphologyEx(img, cv2.MORPH_BLACKHAT, kernel)\n",
        "        else:\n",
        "            raise ValueError(f\"Invalid operation type: {operation_type}\")\n",
        "        if structural == \"yes\":\n",
        "            horizontal_size = 1920 // size\n",
        "            horizontal_structure = cv2.getStructuringElement(cv2.MORPH_RECT, (horizontal_size, 1))\n",
        "            horizontal = out.copy()\n",
        "            out1 = cv2.erode(horizontal, horizontal_structure)\n",
        "            out1 = cv2.dilate(out1, horizontal_structure)\n",
        "            out1 = cv2.bitwise_not(out1)\n",
        "            out = cv2.bitwise_and(out, out1)\n",
        "        cv2.imwrite(os.path.join(w_path, img_name), out)\n",
        "    print(\"Image cleaning completed and results saved to:\", w_path)\n",
        "\n",
        "def EdgeDetection(video, edge_type=\"canny\", kernel=3):\n",
        "    w_path = './Edge-Detection-Results'\n",
        "    r_path = './Image-Cleaning-Results'\n",
        "    os.makedirs(w_path, exist_ok=True)\n",
        "    for img_name in os.listdir(r_path):\n",
        "        if not img_name.endswith(f'_{video}.jpg'):\n",
        "            continue\n",
        "        img_path = os.path.join(r_path, img_name)\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is None:\n",
        "            print(f\"Warning: Unable to read {img_path}. Skipping.\")\n",
        "            continue\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        img_blur = cv2.GaussianBlur(gray, (3, 3), 0)\n",
        "        if edge_type == 'laplacian':\n",
        "            out = cv2.Laplacian(img_blur, cv2.CV_64F, ksize=kernel)\n",
        "            out = cv2.convertScaleAbs(out)\n",
        "        elif edge_type == 'sobelx':\n",
        "            out = cv2.Sobel(img_blur, cv2.CV_64F, 1, 0, ksize=kernel)\n",
        "            out = cv2.convertScaleAbs(out)\n",
        "        elif edge_type == 'sobely':\n",
        "            out = cv2.Sobel(img_blur, cv2.CV_64F, 0, 1, ksize=kernel)\n",
        "            out = cv2.convertScaleAbs(out)\n",
        "        elif edge_type == 'sobelxy':\n",
        "            out = cv2.Sobel(img_blur, cv2.CV_64F, 1, 1, ksize=kernel)\n",
        "            out = cv2.convertScaleAbs(out)\n",
        "        elif edge_type == 'canny':\n",
        "            v = np.mean(img_blur)\n",
        "            sigma = 0.5\n",
        "            lower = int(max(0, (1.0 - sigma) * 30 * v))\n",
        "            upper = int(min(255, (1.0 + sigma) * 30 * v))\n",
        "            out = cv2.Canny(img_blur, lower, upper)\n",
        "        else:\n",
        "            raise ValueError(f\"Invalid edge detection type: {edge_type}\")\n",
        "        cv2.imwrite(os.path.join(w_path, img_name), out)\n",
        "    print(\"Edge detection completed and results saved to:\", w_path)\n"
      ],
      "metadata": {
        "id": "L6b2V_UtkS4x"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **\"Hough Transform-Based Line Detection and Smoothing in Video Frames\"**\n",
        "\n",
        "A comprehensive pipeline for line detection and smoothing in video frames. Using the Hough Transform, it identifies lines in edge-detected frames and processes them to extract the most frequent orientations. The pipeline includes features like default line handling for missing detections, line averaging, and Gaussian smoothing to enhance visual consistency across frames. The results are stored in organized directories, making it suitable for applications such as lane detection, structural analysis, and video post-processing."
      ],
      "metadata": {
        "id": "2mvwzW1U6X7D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_key(mydict, search_val):\n",
        "    for key, value in mydict.items():\n",
        "        if value == search_val:\n",
        "            return key\n",
        "\n",
        "def HoughTransform(video):\n",
        "    c_array = {}\n",
        "    param_array = {}\n",
        "    w_path1 = './Line-Detection-Results/all'\n",
        "    w_path2 = './Line-Detection-Results/max_freq'\n",
        "    r_path = './Edge-Detection-Results'\n",
        "    o_path = './Final-Frames'\n",
        "\n",
        "    os.makedirs(w_path1, exist_ok=True)\n",
        "    os.makedirs(w_path2, exist_ok=True)\n",
        "    os.makedirs(o_path, exist_ok=True)\n",
        "\n",
        "    files = [f for f in os.listdir(r_path) if isfile(join(r_path, f)) and not f.startswith('.') and f.endswith(f'_{video}.jpg')]\n",
        "    files.sort(key=lambda x: int(x[5:-6]))\n",
        "\n",
        "    frame_array = []\n",
        "    avg_length = 100\n",
        "    counter = 0\n",
        "    m_array = {'x1': [], 'x2': [], 'y1': [], 'y2': []}\n",
        "    window = 5\n",
        "    gaussian = [35/1230, 50/1230, 100/1230, 150/1230, 180/1230, 200/1230, 180/1230, 150/1230, 100/1230, 50/1230, 35/1230]\n",
        "\n",
        "    for i, img_name in enumerate(files):\n",
        "        if not img_name.endswith('.jpg'):\n",
        "            continue\n",
        "\n",
        "        frame_no = img_name[5:-6]\n",
        "        original_img = cv2.imread(f'Frames/{img_name}')\n",
        "        img = cv2.imread(f'{r_path}/{img_name}')\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        avg_int = np.mean(gray)\n",
        "\n",
        "        lines = cv2.HoughLinesP(gray, rho=1, theta=np.pi / 180, threshold=60, minLineLength=max(avg_length, 100), maxLineGap=100)\n",
        "\n",
        "        if lines is None or len(lines) <= 0:\n",
        "            draw_default_line(original_img, frame_no, c_array)\n",
        "            continue\n",
        "\n",
        "        process_lines(lines, original_img, frame_no, m_array, c_array)\n",
        "\n",
        "    apply_median_filter(files, m_array, window, o_path)\n",
        "\n",
        "def draw_default_line(original_img, frame_no, c_array):\n",
        "    xa, ya, xb, yb = 0, 0, 0, 0\n",
        "    cv2.line(original_img, (xa, ya), (xb, yb), (0, 0, 255), 3)\n",
        "    cv2.imwrite(f'Line-Detection-Results/all/{frame_no}.jpg', original_img)\n",
        "    c_array[frame_no] = {(float((yb - ya) / (xb - xa + 0.00012))): (xa, ya, xb, yb)}\n",
        "\n",
        "def process_lines(lines, original_img, frame_no, m_array, c_array):\n",
        "    avg_length = 0\n",
        "    line_count = 0\n",
        "    maps = {}\n",
        "\n",
        "    for i in range(len(lines)):\n",
        "        for x1, y1, x2, y2 in lines[i]:\n",
        "            avg_length += math.sqrt((x1 - x2)**2 + (y1 - y2)**2)\n",
        "            cv2.line(original_img, (x1, y1), (x2, y2), (0, 0, 255), 3)\n",
        "            slope = (y2 - y1) / (x2 - x1 + 0.0001)\n",
        "            theta = math.atan(slope)\n",
        "            if theta * 180 / np.pi // 10 not in maps:\n",
        "                maps[theta * 180 / np.pi // 10] = []\n",
        "            maps[theta * 180 / np.pi // 10].append((x1, y1, x2, y2, theta))\n",
        "\n",
        "    avg_length /= len(lines) * 1.17\n",
        "    avg_length += np.random.normal(-10, 10)\n",
        "\n",
        "    max_bin = max(maps.values(), key=len, default=[])\n",
        "    if max_bin:\n",
        "        draw_most_frequent_line(max_bin, original_img, m_array, c_array, frame_no)\n",
        "\n",
        "def draw_most_frequent_line(max_bin, original_img, m_array, c_array, frame_no):\n",
        "    maxi = -math.inf\n",
        "    mini = math.inf\n",
        "    lx1, ly1, lx2, ly2 = max_bin[0][0], max_bin[0][1], max_bin[0][2], max_bin[0][3]\n",
        "\n",
        "    for x1, y1, x2, y2, theta in max_bin:\n",
        "        c = y1 - (y2 - y1) / (x2 - x1 + 0.0001) * x1\n",
        "        if c <= mini:\n",
        "            lx1, ly1, lx2, ly2 = x1, y1, x2, y2\n",
        "            mini = c\n",
        "        elif c >= maxi:\n",
        "            rx1, ry1, rx2, ry2 = x1, y1, x2, y2\n",
        "            maxi = c\n",
        "\n",
        "    xa = int((lx1 + rx1) / 2)\n",
        "    ya = int((ly1 + ry1) / 2)\n",
        "    xb = int((lx2 + rx2) / 2)\n",
        "    yb = int((ly2 + ry2) / 2)\n",
        "    c_array[frame_no] = {(float((yb - ya) / (xb - xa + 0.00012))): (xa, ya, xb, yb)}\n",
        "\n",
        "    m_array['x1'].append(xa)\n",
        "    m_array['x2'].append(xb)\n",
        "    m_array['y1'].append(ya)\n",
        "    m_array['y2'].append(yb)\n",
        "\n",
        "    cv2.line(original_img, (xa, ya), (xb, yb), (0, 0, 255), 3)\n",
        "\n",
        "def apply_median_filter(files, m_array, window, o_path):\n",
        "    avg_coordx1_prev, avg_coordx2_prev, avg_coordy1_prev, avg_coordy2_prev = m_array['x1'][0], m_array['x2'][0], m_array['y1'][0], m_array['y2'][0]\n",
        "    equal_count = 0\n",
        "    flag = True\n",
        "\n",
        "    for i in range(window, len(files) - window):\n",
        "        img_name = files[i]\n",
        "        my_img = cv2.imread(f'Frames/{img_name}')\n",
        "        avg_coordx1 = int(np.average(m_array['x1'][i - window:i + window + 1]))\n",
        "        avg_coordx2 = int(np.average(m_array['x2'][i - window:i + window + 1]))\n",
        "        avg_coordy1 = int(np.average(m_array['y1'][i - window:i + window + 1]))\n",
        "        avg_coordy2 = int(np.average(m_array['y2'][i - window:i + window + 1]))\n",
        "\n",
        "        if (avg_coordx1_prev, avg_coordx2_prev, avg_coordy1_prev, avg_coordy2_prev) == (avg_coordx1, avg_coordx2, avg_coordy1, avg_coordy2):\n",
        "            equal_count += 1\n",
        "            if equal_count <= 3:\n",
        "                cv2.line(my_img, (avg_coordx1_prev + int(2 * np.random.normal()), avg_coordy1_prev + int(2 * np.random.normal())),\n",
        "                         (avg_coordx2_prev + int(2 * np.random.normal()), avg_coordy2_prev + int(2 * np.random.normal())), (0, 0, 255), 3)\n",
        "        else:\n",
        "            if equal_count >= 3 and flag:\n",
        "                equal_count = 2 * window\n",
        "                flag = False\n",
        "            equal_count -= 1\n",
        "            if equal_count <= 0:\n",
        "                flag = True\n",
        "                equal_count = 0\n",
        "                (avg_coordx1_prev, avg_coordx2_prev, avg_coordy1_prev, avg_coordy2_prev) = (avg_coordx1, avg_coordx2, avg_coordy1, avg_coordy2)\n",
        "                cv2.line(my_img, (avg_coordx1_prev, avg_coordy1_prev), (avg_coordx2_prev, avg_coordy2_prev), (0, 0, 255), 3)\n",
        "\n",
        "        cv2.imwrite(f'{o_path}/{img_name}', my_img)\n"
      ],
      "metadata": {
        "id": "JrurVYYVnS48"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **\"Video Creation from Processed Frames\"**\n",
        "\n",
        "\n",
        "1. **Locates Frames**: Reads images from a specified directory that match a given naming pattern.\n",
        "2. **Sorts Frames**: Orders the frames numerically to maintain the correct sequence.\n",
        "3. **Initializes VideoWriter**: Determines the video resolution from the first valid frame and sets up a video writer with the MJPG codec at 30 frames per second.\n",
        "4. **Compiles Frames**: Iteratively writes frames into the video file.\n",
        "5. **Handles Errors**: Skips unreadable frames and exits if no valid frames are found.\n"
      ],
      "metadata": {
        "id": "4dGFO7bw63__"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def SaveVideo(name):\n",
        "    w_path = f'./Result/result_{name}.mp4'\n",
        "    r_path = './Final-Frames'\n",
        "    os.makedirs(os.path.dirname(w_path), exist_ok=True)\n",
        "\n",
        "    files = [f for f in os.listdir(r_path) if isfile(join(r_path, f)) and f.endswith(f'_{name}.jpg')]\n",
        "    files.sort(key=lambda x: int(x[5:-6]))\n",
        "\n",
        "    frame_array = []\n",
        "    size = None\n",
        "\n",
        "    for i, file in enumerate(files):\n",
        "        filename = join(r_path, file)\n",
        "        if i % 100 == 0:\n",
        "            print(f\"Processing: {filename}\")\n",
        "        img = cv2.imread(filename)\n",
        "\n",
        "        if img is None:\n",
        "            print(f\"Error reading file: {filename}\")\n",
        "            continue\n",
        "\n",
        "        if size is None:\n",
        "            height, width, _ = img.shape\n",
        "            size = (width, height)\n",
        "\n",
        "        frame_array.append(img)\n",
        "\n",
        "    if not frame_array:\n",
        "        print(\"No valid frames found. Exiting.\")\n",
        "        return\n",
        "\n",
        "    myvideo = cv2.VideoWriter(w_path, cv2.VideoWriter_fourcc(*'MJPG'), 30, size)\n",
        "\n",
        "    for frame in frame_array:\n",
        "        myvideo.write(frame)\n",
        "\n",
        "    myvideo.release()\n",
        "    print(f\"Video saved to {w_path}\")\n"
      ],
      "metadata": {
        "id": "pWthwph_ogDP"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Important steps: Downloading videos"
      ],
      "metadata": {
        "id": "r05SeAq-jiSS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path = '/content/Videos'\n",
        "\n",
        "if not os.path.exists(folder_path):\n",
        "    os.makedirs(folder_path)\n",
        "\n",
        "file_ids = [\n",
        "    ('1nF6qsYQoygpnj5pL4--J1xAeh_IDGGem', '1.mp4'),\n",
        "    ('1-l2mFlspFh7vNxU8V7tykxnJiJPk7VGT', '2.mp4'),\n",
        "    ('12J5PpOLlsHAY-DqeFjteojc4RO61H6QN', '3.mp4')\n",
        "]\n",
        "\n",
        "for file_id, filename in file_ids:\n",
        "    download_url = f'https://drive.google.com/uc?id={file_id}'\n",
        "    destination = os.path.join(folder_path, filename)\n",
        "    print(f\"Downloading {filename}...\")\n",
        "    gdown.download(download_url, destination, quiet=False)\n",
        "\n",
        "print(\"Download complete!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYTIiRXPjSBU",
        "outputId": "dc068276-35df-4dec-dc9e-d28d18a4822f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 1.mp4...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1nF6qsYQoygpnj5pL4--J1xAeh_IDGGem\n",
            "To: /content/Videos/1.mp4\n",
            "100%|██████████| 6.35M/6.35M [00:00<00:00, 235MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 2.mp4...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-l2mFlspFh7vNxU8V7tykxnJiJPk7VGT\n",
            "To: /content/Videos/2.mp4\n",
            "100%|██████████| 6.08M/6.08M [00:00<00:00, 183MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 3.mp4...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=12J5PpOLlsHAY-DqeFjteojc4RO61H6QN\n",
            "To: /content/Videos/3.mp4\n",
            "100%|██████████| 5.46M/5.46M [00:00<00:00, 192MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download complete!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def process_video_with_options():\n",
        "    \"\"\"\n",
        "    Runs the entire video processing pipeline with user-selected options for arguments.\n",
        "\n",
        "    Returns:\n",
        "    - None\n",
        "    \"\"\"\n",
        "    print(\"Before executing this section make sure that you have executed Important steps: Downloading videos\")\n",
        "    # Step 1: Select video name\n",
        "    print(\"Select a video:\")\n",
        "    print(\"1. Video 1\")\n",
        "    print(\"2. Video 2\")\n",
        "    print(\"3. Video 3\")\n",
        "    video_choice = int(input(\"Choose a video (1-3): \").strip())\n",
        "    video = input(\"Enter the name of the video (without extension): \").strip()\n",
        "\n",
        "    # Step 2: Set varThreshold for BgSubtract\n",
        "    print(\"\\nSet Background Subtraction Threshold (varThreshold):\")\n",
        "    print(\"Options:\")\n",
        "    print(\"1. Low (30)\")\n",
        "    print(\"2. Medium (50)\")\n",
        "    print(\"3. High (70)\")\n",
        "    varThreshold_choice = int(input(\"Choose an option (1-3): \").strip())\n",
        "    varThreshold = {1: 30, 2: 50, 3: 70}.get(varThreshold_choice, 50)  # Default to 50\n",
        "\n",
        "    # Step 3: Cleaning arguments\n",
        "    print(\"\\nSet Cleaning Operation Type:\")\n",
        "    print(\"Options:\")\n",
        "    print(\"1. Erosion\")\n",
        "    print(\"2. Dilation\")\n",
        "    print(\"3. Opening\")\n",
        "    print(\"4. Closing\")\n",
        "    print(\"5. Gradient\")\n",
        "    print(\"6. Tophat\")\n",
        "    print(\"7. Blackhat\")\n",
        "    cleaning_type_choice = int(input(\"Choose an option (1-4): \").strip())\n",
        "    cleaning_type = {1: \"erosion\", 2: \"dilation\", 3: \"opening\", 4: \"closing\", 5: \"gradient\", 6: \"tophat\", 7: \"blackhat\"}.get(cleaning_type_choice, \"opening\")  # Default to opening\n",
        "\n",
        "    kernel_size = int(input(\"\\nEnter kernel size for cleaning (default is 3): \").strip() or 3)\n",
        "    structural = input(\"Apply structural processing? (yes/no, default is no): \").strip().lower() or \"no\"\n",
        "    size = int(input(\"Enter size parameter for structural processing (default is 100): \").strip() or 100)\n",
        "\n",
        "    # Step 4: Edge detection arguments\n",
        "    print(\"\\nSet Edge Detection Type:\")\n",
        "    print(\"Options:\")\n",
        "    print(\"1. Canny\")\n",
        "    print(\"2. Laplacian\")\n",
        "    print(\"3. SobelX\")\n",
        "    print(\"4. SobelY\")\n",
        "    print(\"5. SobelXY\")\n",
        "    edge_type_choice = int(input(\"Choose an option (1-5): \").strip())\n",
        "    edge_type = {1: \"canny\", 2: \"laplacian\", 3: \"sobelx\", 4: \"sobely\", 5: \"sobelxy\"}.get(edge_type_choice, \"canny\")  # Default to canny\n",
        "\n",
        "    # Run the entire process\n",
        "    process_video(\n",
        "        video=video,\n",
        "        varThreshold=varThreshold,\n",
        "        cleaning_type=cleaning_type,\n",
        "        kernel_size=kernel_size,\n",
        "        structural=structural,\n",
        "        size=size,\n",
        "        edge_type=edge_type\n",
        "    )\n",
        "\n",
        "def process_video(video, varThreshold, cleaning_type, kernel_size, structural, size, edge_type):\n",
        "    \"\"\"\n",
        "    Runs the entire video processing pipeline:\n",
        "    1. ExtractFrames\n",
        "    2. BgSubtract\n",
        "    3. Cleaning\n",
        "    4. EdgeDetection\n",
        "    5. HoughTransform\n",
        "    6. SaveVideo\n",
        "\n",
        "    Arguments:\n",
        "    - video (str): The name of the video to process (without extension).\n",
        "    - varThreshold (int): Threshold for background subtraction.\n",
        "    - cleaning_type (str): Cleaning operation type.\n",
        "    - kernel_size (int): Kernel size for cleaning operation.\n",
        "    - structural (str): Apply structural processing ('yes' or 'no').\n",
        "    - size (int): Size parameter for structural processing.\n",
        "    - edge_type (str): Type of edge detection.\n",
        "\n",
        "    Returns:\n",
        "    - None\n",
        "    \"\"\"\n",
        "    # Step 1: Extract frames from the video\n",
        "    print(\"Step 1: Extracting frames...\")\n",
        "    fps = ExtractFrames(video)\n",
        "    print(f\"Frames extracted with {fps} FPS.\")\n",
        "\n",
        "    # Step 2: Perform background subtraction\n",
        "    print(\"Step 2: Background subtraction...\")\n",
        "    BgSubtract(video, fps, varThreshold)\n",
        "    print(\"Background subtraction completed.\")\n",
        "\n",
        "    # Step 3: Clean the images\n",
        "    print(\"Step 3: Cleaning images...\")\n",
        "    Cleaning(video, cleaning_type, kernel_size, structural, size)\n",
        "    print(\"Image cleaning completed.\")\n",
        "\n",
        "    # Step 4: Perform edge detection\n",
        "    print(\"Step 4: Edge detection...\")\n",
        "    EdgeDetection(video, edge_type, 3)\n",
        "    print(\"Edge detection completed.\")\n",
        "\n",
        "    # Step 5: Detect lines using Hough Transform\n",
        "    print(\"Step 5: Line detection using Hough Transform...\")\n",
        "    HoughTransform(video)\n",
        "    print(\"Line detection completed.\")\n",
        "\n",
        "    # Step 6: Save the processed frames as a video\n",
        "    print(\"Step 6: Saving video...\")\n",
        "    SaveVideo(video)\n",
        "    print(\"Video saved successfully.\")\n",
        "\n",
        "    shutil.rmtree('/content/Frames')\n",
        "    shutil.rmtree('/content/Background-Subtraction-Frames')\n",
        "    shutil.rmtree('/content/Image-Cleaning-Results')\n",
        "    shutil.rmtree('/content/Edge-Detection-Results')\n",
        "    shutil.rmtree('/content/Final-Frames')\n",
        "    shutil.rmtree('/content/Line-Detection-Results')\n",
        "\n",
        "# Run the process with options\n",
        "process_video_with_options()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCz-Q1v0xDb1",
        "outputId": "37825408-2e30-41a1-946f-ddf8b7a81de9"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before executing this section make sure that you have executed Important steps: Downloading videos\n",
            "Select a video:\n",
            "1. Video 1\n",
            "2. Video 2\n",
            "3. Video 3\n",
            "Choose a video (1-3): 1\n",
            "Enter the name of the video (without extension): 1\n",
            "\n",
            "Set Background Subtraction Threshold (varThreshold):\n",
            "Options:\n",
            "1. Low (30)\n",
            "2. Medium (50)\n",
            "3. High (70)\n",
            "Choose an option (1-3): 1\n",
            "\n",
            "Set Cleaning Operation Type:\n",
            "Options:\n",
            "1. Erosion\n",
            "2. Dilation\n",
            "3. Opening\n",
            "4. Closing\n",
            "5. Gradient\n",
            "6. Tophat\n",
            "7. Blackhat\n",
            "Choose an option (1-4): 4\n",
            "\n",
            "Enter kernel size for cleaning (default is 3): 3\n",
            "Apply structural processing? (yes/no, default is no): no\n",
            "Enter size parameter for structural processing (default is 100): 100\n",
            "\n",
            "Set Edge Detection Type:\n",
            "Options:\n",
            "1. Canny\n",
            "2. Laplacian\n",
            "3. SobelX\n",
            "4. SobelY\n",
            "5. SobelXY\n",
            "Choose an option (1-5): 5\n",
            "Step 1: Extracting frames...\n",
            "Frames per second: 30.0\n",
            "Number of frames: 463\n",
            "Frames extracted with 30.0 FPS.\n",
            "Step 2: Background subtraction...\n",
            "Background subtraction completed and images saved to: ./Background-Subtraction-Frames\n",
            "Background subtraction completed.\n",
            "Step 3: Cleaning images...\n",
            "Image cleaning completed and results saved to: ./Image-Cleaning-Results\n",
            "Image cleaning completed.\n",
            "Step 4: Edge detection...\n",
            "Edge detection completed and results saved to: ./Edge-Detection-Results\n",
            "Edge detection completed.\n",
            "Step 5: Line detection using Hough Transform...\n",
            "Line detection completed.\n",
            "Step 6: Saving video...\n",
            "Processing: ./Final-Frames/Frame5_1.jpg\n",
            "Processing: ./Final-Frames/Frame105_1.jpg\n",
            "Processing: ./Final-Frames/Frame205_1.jpg\n",
            "Processing: ./Final-Frames/Frame305_1.jpg\n",
            "Processing: ./Final-Frames/Frame405_1.jpg\n",
            "Video saved to ./Result/result_1.mp4\n",
            "Video saved successfully.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}